{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_language_urls, get_all_urls, get_repo_content\n",
    "from prepare import prep_repo_data\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    '''\n",
    "    This helper function takes in a url and requests and parses HTML\n",
    "    returning a soup object.\n",
    "    '''\n",
    "    headers = {'User-Agent': 'Sir Galahad'} \n",
    "    response = get(url, headers=headers)    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_urls(n,m):\n",
    "    '''\n",
    "    This function scrapes the GH search results for most starred \n",
    "    pages from each language from page n to m pages of each \n",
    "    and returns a list of urls.\n",
    "    '''\n",
    "    # create empty list to hold urls\n",
    "    urls = []\n",
    "    # create list of languages to search for\n",
    "    languages = ['JavaScript', 'Python']\n",
    "    # loop through the languages\n",
    "    for language in languages:\n",
    "        # loop throught the page numbers\n",
    "        for i in range(n,m+1):\n",
    "            # each page for most starred repos on GH\n",
    "            url = f'https://github.com/search?l={language}&p={i}&q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "            # append the url to the urls list\n",
    "            urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first 15 search pages of urls for JS and Python\n",
    "#search_urls = get_language_urls(1,15)\n",
    "#search_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second 15 search pages of urls for JS and Python\n",
    "#search_urls2 =get_language_urls(16, 30)\n",
    "#search_urls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/search?l=JavaScript&p=31&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=32&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=33&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=34&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=35&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=36&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=37&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=38&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=39&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=40&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=31&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=32&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=33&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=34&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=35&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=36&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=37&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=38&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=39&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=40&q=stars%3A%3E0&s=stars&type=Repositories']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next 10 pages of urls for JS and Python\n",
    "search_urls3 = get_language_urls(31, 40)\n",
    "search_urls3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls(urls):\n",
    "    '''\n",
    "    This function scrapes all of the urls from\n",
    "    the GH search results pages and returns a complete list of urls.\n",
    "    '''\n",
    "    # create empty list\n",
    "    repo_urls = []\n",
    "    n=0\n",
    "    # loop through each url in urls list\n",
    "    for url in urls:\n",
    "        # Make request and soup object using helper function\n",
    "        soup = make_soup(url)\n",
    "        # delay 1 second between fetch\n",
    "        sleep(8)\n",
    "        n = n + 1\n",
    "        print(f\"Scraping loop number {n}\")\n",
    "        # Create a list of the anchor elements that hold the urls.\n",
    "        urls_list = soup.find_all('a', class_='v-align-middle')\n",
    "        # I'm using a set comprehension to return only unique urls.\n",
    "        urls_set = {'https://github.com' + link.get('href') for link in urls_list}\n",
    "        # I'm converting my set to a list of urls.\n",
    "        urls_set = list(urls_set)\n",
    "        # extend the list with a new url as an element\n",
    "        repo_urls.extend(urls_set)        \n",
    "    return repo_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping loop number 1\n",
      "Scraping loop number 2\n",
      "Scraping loop number 3\n",
      "Scraping loop number 4\n",
      "Scraping loop number 5\n",
      "Scraping loop number 6\n",
      "Scraping loop number 7\n",
      "Scraping loop number 8\n",
      "Scraping loop number 9\n",
      "Scraping loop number 10\n",
      "Scraping loop number 11\n",
      "Scraping loop number 12\n",
      "Scraping loop number 13\n",
      "Scraping loop number 14\n",
      "Scraping loop number 15\n",
      "Scraping loop number 16\n",
      "Scraping loop number 17\n",
      "Scraping loop number 18\n",
      "Scraping loop number 19\n",
      "Scraping loop number 20\n"
     ]
    }
   ],
   "source": [
    "#all_urls = get_all_urls(search_urls)\n",
    "#all_urls2 = get_all_urls(search_urls2)\n",
    "all_urls3 = get_all_urls(search_urls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(all_urls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_urls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list1 = all_urls[0:101]\n",
    "#list2 = all_urls[101:201]\n",
    "#list3 = all_urls[201:301]\n",
    "#list1 + list2 + list3 == all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list4 = all_urls2[0:100]\n",
    "#list5 = all_urls2[100:200]\n",
    "#list6 = all_urls2[200:301]\n",
    "#list4 + list5 + list6 == all_urls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(list4), len(list5), len(list6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_content(urls, cached=False):\n",
    "    '''\n",
    "    This function takes in a list of Github urls and a parameter\n",
    "    with default cached == False which scrapes the language and  \n",
    "    readme text for each url, creates a list of dictionaries with \n",
    "    the title and text for each blog, converts list to df, and returns \n",
    "    df. If cached == True, the function returns a df from a json file.\n",
    "    '''\n",
    "    if cached == True:\n",
    "        df = pd.read_json('gh_repos.json')\n",
    "        \n",
    "    # cached == False completes a fresh scrape for df     \n",
    "    else:\n",
    "\n",
    "        # Create an empty list to hold dictionaries\n",
    "        articles = []\n",
    "        n=0\n",
    "        # Loop through each url in our list of urls\n",
    "        for url in urls:\n",
    "\n",
    "            # Make request and soup object using helper\n",
    "            soup = make_soup(url)\n",
    "            sleep(1)\n",
    "            n = n + 1\n",
    "            print(f\"Scraping loop number {n}\")\n",
    "            \n",
    "            # Save the programming language of each repo in variable language\n",
    "            language = soup.find('span', class_='text-gray-dark text-bold mr-1').text\n",
    "\n",
    "            # Save the repo sub url\n",
    "            repo = url[19:]\n",
    "            \n",
    "            # Save the text in each repo to variable content\n",
    "            content = soup.find('article', class_=\"markdown-body entry-content container-lg\").text\n",
    "\n",
    "            # Create a dictionary holding the title and content for each blog\n",
    "            article = {'language': language, 'repo': repo, 'content': content}\n",
    "\n",
    "            # Add each dictionary to the articles list of dictionaries\n",
    "            articles.append(article)\n",
    "            \n",
    "        # convert our list of dictionaries to a df\n",
    "        df = pd.DataFrame(articles)\n",
    "\n",
    "        # Write df to a json file for faster access\n",
    "        df.to_json('gh_repos_test.json')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh_repos.json\n",
    "#df1 = get_repo_content(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh_repos2.json\n",
    "#df2 = get_repo_content(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh_repos3.json\n",
    "#df3 = get_repo_content(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh_repos4.json\n",
    "#df4 = get_repo_content(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh_repos5.json\n",
    "#df5 = get_repo_content(list5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gh_repos6.json\n",
    "#df6 = get_repo_content(list6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping loop number 1\n",
      "Scraping loop number 2\n",
      "Scraping loop number 3\n",
      "Scraping loop number 4\n",
      "Scraping loop number 5\n",
      "Scraping loop number 6\n",
      "Scraping loop number 7\n",
      "Scraping loop number 8\n",
      "Scraping loop number 9\n",
      "Scraping loop number 10\n",
      "Scraping loop number 11\n",
      "Scraping loop number 12\n",
      "Scraping loop number 13\n",
      "Scraping loop number 14\n",
      "Scraping loop number 15\n",
      "Scraping loop number 16\n",
      "Scraping loop number 17\n",
      "Scraping loop number 18\n",
      "Scraping loop number 19\n",
      "Scraping loop number 20\n",
      "Scraping loop number 21\n",
      "Scraping loop number 22\n",
      "Scraping loop number 23\n",
      "Scraping loop number 24\n",
      "Scraping loop number 25\n",
      "Scraping loop number 26\n",
      "Scraping loop number 27\n",
      "Scraping loop number 28\n",
      "Scraping loop number 29\n",
      "Scraping loop number 30\n",
      "Scraping loop number 31\n",
      "Scraping loop number 32\n",
      "Scraping loop number 33\n",
      "Scraping loop number 34\n",
      "Scraping loop number 35\n",
      "Scraping loop number 36\n",
      "Scraping loop number 37\n",
      "Scraping loop number 38\n",
      "Scraping loop number 39\n",
      "Scraping loop number 40\n",
      "Scraping loop number 41\n",
      "Scraping loop number 42\n",
      "Scraping loop number 43\n",
      "Scraping loop number 44\n",
      "Scraping loop number 45\n",
      "Scraping loop number 46\n",
      "Scraping loop number 47\n",
      "Scraping loop number 48\n",
      "Scraping loop number 49\n",
      "Scraping loop number 50\n",
      "Scraping loop number 51\n",
      "Scraping loop number 52\n",
      "Scraping loop number 53\n",
      "Scraping loop number 54\n",
      "Scraping loop number 55\n",
      "Scraping loop number 56\n",
      "Scraping loop number 57\n",
      "Scraping loop number 58\n",
      "Scraping loop number 59\n",
      "Scraping loop number 60\n",
      "Scraping loop number 61\n",
      "Scraping loop number 62\n",
      "Scraping loop number 63\n",
      "Scraping loop number 64\n",
      "Scraping loop number 65\n",
      "Scraping loop number 66\n",
      "Scraping loop number 67\n",
      "Scraping loop number 68\n",
      "Scraping loop number 69\n",
      "Scraping loop number 70\n",
      "Scraping loop number 71\n",
      "Scraping loop number 72\n",
      "Scraping loop number 73\n",
      "Scraping loop number 74\n",
      "Scraping loop number 75\n",
      "Scraping loop number 76\n",
      "Scraping loop number 77\n",
      "Scraping loop number 78\n",
      "Scraping loop number 79\n",
      "Scraping loop number 80\n",
      "Scraping loop number 81\n",
      "Scraping loop number 82\n",
      "Scraping loop number 83\n",
      "Scraping loop number 84\n",
      "Scraping loop number 85\n",
      "Scraping loop number 86\n",
      "Scraping loop number 87\n",
      "Scraping loop number 88\n",
      "Scraping loop number 89\n",
      "Scraping loop number 90\n",
      "Scraping loop number 91\n",
      "Scraping loop number 92\n",
      "Scraping loop number 93\n",
      "Scraping loop number 94\n",
      "Scraping loop number 95\n",
      "Scraping loop number 96\n",
      "Scraping loop number 97\n",
      "Scraping loop number 98\n",
      "Scraping loop number 99\n",
      "Scraping loop number 100\n",
      "Scraping loop number 101\n",
      "Scraping loop number 102\n",
      "Scraping loop number 103\n",
      "Scraping loop number 104\n",
      "Scraping loop number 105\n",
      "Scraping loop number 106\n",
      "Scraping loop number 107\n",
      "Scraping loop number 108\n",
      "Scraping loop number 109\n",
      "Scraping loop number 110\n",
      "Scraping loop number 111\n",
      "Scraping loop number 112\n",
      "Scraping loop number 113\n",
      "Scraping loop number 114\n",
      "Scraping loop number 115\n",
      "Scraping loop number 116\n",
      "Scraping loop number 117\n",
      "Scraping loop number 118\n",
      "Scraping loop number 119\n",
      "Scraping loop number 120\n",
      "Scraping loop number 121\n",
      "Scraping loop number 122\n",
      "Scraping loop number 123\n",
      "Scraping loop number 124\n",
      "Scraping loop number 125\n",
      "Scraping loop number 126\n",
      "Scraping loop number 127\n",
      "Scraping loop number 128\n",
      "Scraping loop number 129\n",
      "Scraping loop number 130\n",
      "Scraping loop number 131\n",
      "Scraping loop number 132\n",
      "Scraping loop number 133\n",
      "Scraping loop number 134\n",
      "Scraping loop number 135\n",
      "Scraping loop number 136\n",
      "Scraping loop number 137\n",
      "Scraping loop number 138\n",
      "Scraping loop number 139\n",
      "Scraping loop number 140\n",
      "Scraping loop number 141\n",
      "Scraping loop number 142\n",
      "Scraping loop number 143\n",
      "Scraping loop number 144\n",
      "Scraping loop number 145\n",
      "Scraping loop number 146\n",
      "Scraping loop number 147\n",
      "Scraping loop number 148\n",
      "Scraping loop number 149\n",
      "Scraping loop number 150\n",
      "Scraping loop number 151\n",
      "Scraping loop number 152\n",
      "Scraping loop number 153\n",
      "Scraping loop number 154\n",
      "Scraping loop number 155\n",
      "Scraping loop number 156\n",
      "Scraping loop number 157\n",
      "Scraping loop number 158\n",
      "Scraping loop number 159\n",
      "Scraping loop number 160\n",
      "Scraping loop number 161\n",
      "Scraping loop number 162\n",
      "Scraping loop number 163\n",
      "Scraping loop number 164\n",
      "Scraping loop number 165\n",
      "Scraping loop number 166\n",
      "Scraping loop number 167\n",
      "Scraping loop number 168\n",
      "Scraping loop number 169\n",
      "Scraping loop number 170\n",
      "Scraping loop number 171\n",
      "Scraping loop number 172\n",
      "Scraping loop number 173\n",
      "Scraping loop number 174\n",
      "Scraping loop number 175\n",
      "Scraping loop number 176\n",
      "Scraping loop number 177\n",
      "Scraping loop number 178\n",
      "Scraping loop number 179\n",
      "Scraping loop number 180\n",
      "Scraping loop number 181\n",
      "Scraping loop number 182\n",
      "Scraping loop number 183\n",
      "Scraping loop number 184\n",
      "Scraping loop number 185\n",
      "Scraping loop number 186\n",
      "Scraping loop number 187\n",
      "Scraping loop number 188\n",
      "Scraping loop number 189\n",
      "Scraping loop number 190\n",
      "Scraping loop number 191\n",
      "Scraping loop number 192\n",
      "Scraping loop number 193\n",
      "Scraping loop number 194\n",
      "Scraping loop number 195\n",
      "Scraping loop number 196\n",
      "Scraping loop number 197\n",
      "Scraping loop number 198\n",
      "Scraping loop number 199\n",
      "Scraping loop number 200\n"
     ]
    }
   ],
   "source": [
    "#gh_repos_test.json\n",
    "df_test = get_repo_content(all_urls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df1 = pd.read_json('gh_repos.json')\n",
    "df2 = pd.read_json('gh_repos2.json')\n",
    "df3 = pd.read_json('gh_repos3.json')\n",
    "df4 = pd.read_json('gh_repos4.json')\n",
    "df5 = pd.read_json('gh_repos5.json')\n",
    "df6 = pd.read_json('gh_repos6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.concat([df1, df2, df3, df4, df5, df6]).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>repo</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>knex/knex</td>\n",
       "      <td>knex.js\\n\\n\\n\\n\\n\\n\\n\\n\\nA SQL query builder t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>substack/stream-handbook</td>\n",
       "      <td>stream-handbook\\nThis document covers the basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>angular/angular-seed</td>\n",
       "      <td>angular-seed — the seed for AngularJS apps\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>qianguyihao/Web</td>\n",
       "      <td>项目介绍\\n项目地址：https://github.com/qianguyihao/Web\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>browserify/browserify</td>\n",
       "      <td>browserify\\nrequire('modules') in the browser\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                      repo  \\\n",
       "0  JavaScript                 knex/knex   \n",
       "1  JavaScript  substack/stream-handbook   \n",
       "2  JavaScript      angular/angular-seed   \n",
       "3  JavaScript           qianguyihao/Web   \n",
       "4  JavaScript     browserify/browserify   \n",
       "\n",
       "                                             content  \n",
       "0  knex.js\\n\\n\\n\\n\\n\\n\\n\\n\\nA SQL query builder t...  \n",
       "1  stream-handbook\\nThis document covers the basi...  \n",
       "2  angular-seed — the seed for AngularJS apps\\nTh...  \n",
       "3  项目介绍\\n项目地址：https://github.com/qianguyihao/Web\\...  \n",
       "4  browserify\\nrequire('modules') in the browser\\...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MorvanZhou/Reinforcement-learning-with-tensorflow    1\n",
       "facebookresearch/pytext                              1\n",
       "newsapps/beeswithmachineguns                         1\n",
       "qqwweee/keras-yolo3                                  1\n",
       "netlify/netlify-cms                                  1\n",
       "                                                    ..\n",
       "ajenti/ajenti                                        1\n",
       "pyeve/eve                                            1\n",
       "infinitered/reactotron                               1\n",
       "bup/bup                                              1\n",
       "boto/boto3                                           1\n",
       "Name: repo, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.repo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_json('repos.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = prep_repo_data(df_test, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df.to_json('test_repos_clean.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>repo</th>\n",
       "      <th>content</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>knex/knex</td>\n",
       "      <td>knex.js\\n\\n\\n\\n\\n\\n\\n\\n\\nA SQL query builder t...</td>\n",
       "      <td>knexj a sql queri builder that is flexibl port...</td>\n",
       "      <td>knexjs a sql query builder that is flexible po...</td>\n",
       "      <td>knexjs sql query builder flexible portable fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>substack/stream-handbook</td>\n",
       "      <td>stream-handbook\\nThis document covers the basi...</td>\n",
       "      <td>streamhandbook thi document cover the basic of...</td>\n",
       "      <td>streamhandbook this document cover the basic o...</td>\n",
       "      <td>streamhandbook document cover basic write node...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>angular/angular-seed</td>\n",
       "      <td>angular-seed — the seed for AngularJS apps\\nTh...</td>\n",
       "      <td>angularse the seed for angularj app thi projec...</td>\n",
       "      <td>angularseed the seed for angularjs apps this p...</td>\n",
       "      <td>angularseed seed angularjs apps project applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>qianguyihao/Web</td>\n",
       "      <td>项目介绍\\n项目地址：https://github.com/qianguyihao/Web\\...</td>\n",
       "      <td>httpsgithubcomqianguyihaoweb 1 2 3 androidweb ...</td>\n",
       "      <td>httpsgithubcomqianguyihaoweb 1 2 3 androidweb ...</td>\n",
       "      <td>httpsgithubcomqianguyihaoweb 1 2 3 androidweb ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>browserify/browserify</td>\n",
       "      <td>browserify\\nrequire('modules') in the browser\\...</td>\n",
       "      <td>browserifi requiremodul in the browser use a n...</td>\n",
       "      <td>browserify requiremodules in the browser use a...</td>\n",
       "      <td>browserify requiremodules browser use nodestyl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                      repo  \\\n",
       "0  JavaScript                 knex/knex   \n",
       "1  JavaScript  substack/stream-handbook   \n",
       "2  JavaScript      angular/angular-seed   \n",
       "3  JavaScript           qianguyihao/Web   \n",
       "4  JavaScript     browserify/browserify   \n",
       "\n",
       "                                             content  \\\n",
       "0  knex.js\\n\\n\\n\\n\\n\\n\\n\\n\\nA SQL query builder t...   \n",
       "1  stream-handbook\\nThis document covers the basi...   \n",
       "2  angular-seed — the seed for AngularJS apps\\nTh...   \n",
       "3  项目介绍\\n项目地址：https://github.com/qianguyihao/Web\\...   \n",
       "4  browserify\\nrequire('modules') in the browser\\...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  knexj a sql queri builder that is flexibl port...   \n",
       "1  streamhandbook thi document cover the basic of...   \n",
       "2  angularse the seed for angularj app thi projec...   \n",
       "3  httpsgithubcomqianguyihaoweb 1 2 3 androidweb ...   \n",
       "4  browserifi requiremodul in the browser use a n...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  knexjs a sql query builder that is flexible po...   \n",
       "1  streamhandbook this document cover the basic o...   \n",
       "2  angularseed the seed for angularjs apps this p...   \n",
       "3  httpsgithubcomqianguyihaoweb 1 2 3 androidweb ...   \n",
       "4  browserify requiremodules in the browser use a...   \n",
       "\n",
       "                                               clean  \n",
       "0  knexjs sql query builder flexible portable fun...  \n",
       "1  streamhandbook document cover basic write node...  \n",
       "2  angularseed seed angularjs apps project applic...  \n",
       "3  httpsgithubcomqianguyihaoweb 1 2 3 androidweb ...  \n",
       "4  browserify requiremodules browser use nodestyl...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
