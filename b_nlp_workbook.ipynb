{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project\n",
    "\n",
    ">Goals:\n",
    "- Build a dataset of 100 Github repositories' readme text\n",
    "- Explore the text of the readme's and find connections to programming language\n",
    "- Build a classification ML model that predicts the programming language used in a repo based on readme content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# acquire\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "# prepare\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# explore\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# model\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    '''\n",
    "    This helper function takes in a url and requests and parses HTML\n",
    "    returning a soup object.\n",
    "    '''\n",
    "    headers = {'User-Agent': 'Sir Galahad'} \n",
    "    response = get(url, headers=headers)    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_urls():\n",
    "    '''\n",
    "    This function scrapes all of the Codeup blog urls from\n",
    "    the main Codeup blog page and returns a list of urls.\n",
    "    '''\n",
    "    \n",
    "    urls = []\n",
    "    \n",
    "    languages = ['JavaScript', 'Python', 'Java', 'HTML']\n",
    "    \n",
    "    for language in languages:\n",
    "        for i in range(1,11):\n",
    "            # first page for most starred repos on GH\n",
    "            url = f'https://github.com/search?l={language}&p={i}&q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "\n",
    "            urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_language_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/search?l=JavaScript&p=1&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=JavaScript&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=1&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Python&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=1&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=Java&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=1&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
       " 'https://github.com/search?l=HTML&p=10&q=stars%3A%3E0&s=stars&type=Repositories']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls(urls):\n",
    "    '''\n",
    "    This function scrapes all of the Codeup blog urls from\n",
    "    the main Codeup blog page and returns a list of urls.\n",
    "    '''\n",
    "    \n",
    "    repo_urls = []\n",
    "    \n",
    "    for url in urls:\n",
    "        # Make request and soup object using helper\n",
    "        soup = make_soup(url)\n",
    "        sleep(1)\n",
    "        # Create a list of the anchor elements that hold the urls.\n",
    "        urls_list = soup.find_all('a', class_='v-align-middle')\n",
    "    \n",
    "        # I'm using a set comprehension to return only unique urls.\n",
    "        urls_set = {'https://github.com' + link.get('href') for link in urls_list}\n",
    "        urls_set = list(urls_set)\n",
    "        repo_urls.extend(urls_set)\n",
    "\n",
    "    # I'm converting my set to a list of urls.\n",
    "    # urls = list(urls) \n",
    "        \n",
    "    return repo_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = get_all_urls(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(urls, cached=False):\n",
    "    '''\n",
    "    This function takes in a list of Codeup Blog urls and a parameter\n",
    "    with default cached == False which scrapes the title and text for each url, \n",
    "    creates a list of dictionaries with the title and text for each blog, \n",
    "    converts list to df, and returns df.\n",
    "    If cached == True, the function returns a df from a json file.\n",
    "    '''\n",
    "    if cached == True:\n",
    "        df = pd.read_json('github_repos.json')\n",
    "        \n",
    "    # cached == False completes a fresh scrape for df     \n",
    "    else:\n",
    "\n",
    "        # Create an empty list to hold dictionaries\n",
    "        articles = []\n",
    "\n",
    "        # Loop through each url in our list of urls\n",
    "        for url in urls:\n",
    "\n",
    "            # Make request and soup object using helper\n",
    "            soup = make_soup(url)\n",
    "\n",
    "            # Save the programming language of each repo in variable language\n",
    "            language = soup.find('span', class_='text-gray-dark text-bold mr-1').text\n",
    "\n",
    "            # Save the text in each repo to variable content\n",
    "            content = soup.find('article', class_=\"markdown-body entry-content container-lg\").text\n",
    "\n",
    "            # Create a dictionary holding the title and content for each blog\n",
    "            article = {'language': language, 'content': content}\n",
    "\n",
    "            # Add each dictionary to the articles list of dictionaries\n",
    "            articles.append(article)\n",
    "            \n",
    "        # convert our list of dictionaries to a df\n",
    "        df = pd.DataFrame(articles)\n",
    "\n",
    "        # Write df to a json file for faster access\n",
    "        df.to_json('github_repos.json')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_blog_articles(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('github_repos.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Airbnb JavaScript Style Guide() {\\nA mostly re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Create React App  \\n\\nCreate React apps with n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                            content\n",
       "0  JavaScript  \\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...\n",
       "1  JavaScript  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...\n",
       "2  JavaScript  \\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...\n",
       "3  JavaScript  Airbnb JavaScript Style Guide() {\\nA mostly re...\n",
       "4  JavaScript  Create React App  \\n\\nCreate React apps with n..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript    70\n",
       "Java          50\n",
       "Python        40\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKC', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string\n",
    "\n",
    "##############################\n",
    "\n",
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string\n",
    "\n",
    "#############################\n",
    "\n",
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string\n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string\n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "\n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords\n",
    "\n",
    "###############################\n",
    "\n",
    "\n",
    "def prep_repo_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\\\n",
    "                            .apply(lemmatize)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean).apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean).apply(lemmatize)\n",
    "    \n",
    "    return df[['language', column, 'stemmed', 'lemmatized', 'clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_repo_data(df, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...</td>\n",
       "      <td>bootstrap sleek intuit and power frontend fram...</td>\n",
       "      <td>bootstrap sleek intuitive and powerful fronten...</td>\n",
       "      <td>bootstrap sleek intuitive powerful frontend fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...</td>\n",
       "      <td>support vuej vuej is an mitlicens open sourc p...</td>\n",
       "      <td>supporting vuejs vuejs is an mitlicensed open ...</td>\n",
       "      <td>supporting vuejs vuejs mitlicensed open source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...</td>\n",
       "      <td>freecodecamporg opensourc codebas and curricul...</td>\n",
       "      <td>freecodecamporgs opensource codebase and curri...</td>\n",
       "      <td>freecodecamporgs opensource codebase curriculu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Airbnb JavaScript Style Guide() {\\nA mostly re...</td>\n",
       "      <td>airbnb javascript style guid a mostli reason a...</td>\n",
       "      <td>airbnb javascript style guide a mostly reasona...</td>\n",
       "      <td>airbnb javascript style guide mostly reasonabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Create React App  \\n\\nCreate React apps with n...</td>\n",
       "      <td>creat react app creat react app with no build ...</td>\n",
       "      <td>create react app create react apps with no bui...</td>\n",
       "      <td>create react app create react apps build confi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                            content  \\\n",
       "0  JavaScript  \\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...   \n",
       "1  JavaScript  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...   \n",
       "2  JavaScript  \\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...   \n",
       "3  JavaScript  Airbnb JavaScript Style Guide() {\\nA mostly re...   \n",
       "4  JavaScript  Create React App  \\n\\nCreate React apps with n...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  bootstrap sleek intuit and power frontend fram...   \n",
       "1  support vuej vuej is an mitlicens open sourc p...   \n",
       "2  freecodecamporg opensourc codebas and curricul...   \n",
       "3  airbnb javascript style guid a mostli reason a...   \n",
       "4  creat react app creat react app with no build ...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  bootstrap sleek intuitive and powerful fronten...   \n",
       "1  supporting vuejs vuejs is an mitlicensed open ...   \n",
       "2  freecodecamporgs opensource codebase and curri...   \n",
       "3  airbnb javascript style guide a mostly reasona...   \n",
       "4  create react app create react apps with no bui...   \n",
       "\n",
       "                                               clean  \n",
       "0  bootstrap sleek intuitive powerful frontend fr...  \n",
       "1  supporting vuejs vuejs mitlicensed open source...  \n",
       "2  freecodecamporgs opensource codebase curriculu...  \n",
       "3  airbnb javascript style guide mostly reasonabl...  \n",
       "4  create react app create react apps build confi...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
